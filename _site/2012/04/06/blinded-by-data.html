<p>Today's product design jargon makes frequent use of the term "data-driven". Our decisions on what to design and build must come from data to be justified as sound. Otherwise, we'd be relying on vague intuition. Never a good thing.</p>

<p>Of course, this analogy derives from computers. Computers acquire, process and re-output data like we humans breath, eat, read and interact with one another. If we treat life experience like data and accurately interpret it, our difficult decisions get reduced to neat logical equations. Foolish, human error is eliminated. Following this impeccable decision-tree all our solutions become perfect and correct. Thank you Spock.</p>

<p><em>End sarcasm</em></p>

<p>I love analogies, but this one is ironic. In formatting our minds to conform to the rules of data, we are modeling ourselves after tools that we humans first invented ~50 years ago to accelerate repetitive tasks. Computers were designed by us to serve us. So, isn't it odd to suggest we should mimic our machines and adopt the simplified language we invented for their development? The language of computers is binary – a reduced set of instructions devoid of human intuition - the same intuition at the heart of every great human invention. Computer data is a minified language and wholly inadequate to address all  variables involved in human decision-making. Indeed, the purpose for data in software design seems merely to comfort investors and managers, to quell their anxieties around all forms of risk, an inevitable and beautiful part of everyday existence. The big-data movement at the root of Facebook's behavioral advertising and Google's product decisions alike, lull those companies to feel there is reduced risk, that the computed solution must be the correct one since it is channeled through analytical algorithms. Ugh.</p>

<p>Computers are our assistants. They are a work in progress, at least hundreds if not thousands of years from achieving human complexity and our unique process of conscious and subconscious thought combined with over 7 billion points of collaborative communication. But computers don't stand a chance of advancing if we, the inventors, keep looking to them to automate the answers. Patterning our mental processes to mimic computers – still relatively primitive in the scope of human evolution – is not only ironic, it's moronic.</p>

<p><strong><em>Follow-up: Dec 31, 2012</em></strong></p>

<p>Good to see the sentiment echoed by a <a href="http://www.nytimes.com/2012/12/30/technology/big-data-is-great-but-dont-forget-intuition.html?ref=technology&amp;_r=0">select few</a>.</p>
